{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TME 2 - 2 : Inférence collective\n",
    "\n",
    "## Partie 1 - Classifieur local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== url dataframe ===\n",
      "0                           http://robios8.me.wisc.edu\n",
      "1    http://robios8.me.wisc.edu/~lumelsky/lumelsky....\n",
      "2                      http://www.cae.wisc.edu/~ece552\n",
      "3                               http://www.cs.wisc.edu\n",
      "4                        http://www.cs.wisc.edu/condor\n",
      "Name: 0, dtype: object\n",
      "\n",
      "=== labels dataframe ===\n",
      "0    project\n",
      "1    faculty\n",
      "2     course\n",
      "3     course\n",
      "4    project\n",
      "Name: 1704, dtype: object\n",
      "\n",
      "=== attributes dataframe ===\n",
      "   1     2     3     4     5     6     7     8     9     10    ...   1694  \\\n",
      "0     0     0     0     0     0     0     0     0     1     0  ...      0   \n",
      "1     0     0     0     0     0     0     0     0     1     0  ...      0   \n",
      "2     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
      "3     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
      "4     0     0     0     0     0     0     0     0     1     0  ...      0   \n",
      "\n",
      "   1695  1696  1697  1698  1699  1700  1701  1702  1703  \n",
      "0     0     0     0     0     0     0     0     1     0  \n",
      "1     0     0     0     0     0     0     0     0     0  \n",
      "2     0     0     0     0     0     0     1     0     0  \n",
      "3     0     0     0     0     0     1     0     0     0  \n",
      "4     0     0     0     0     0     0     0     1     0  \n",
      "\n",
      "[5 rows x 1703 columns]\n",
      "\n",
      "Unlabeled items:\n",
      "['http://www.cs.wisc.edu/~solomon/solomon.html'\n",
      " 'http://www.cs.wisc.edu/~seitz/interp/interp.html'\n",
      " 'http://www.cs.wisc.edu/~hasti/hasti.html'\n",
      " 'http://www.cs.wisc.edu/~dzimm/cs302.html'\n",
      " 'http://www.cs.wisc.edu/~cs513-1/cs513.html'\n",
      " 'http://www.cs.wisc.edu/~hasti/hasti.html'\n",
      " 'http://www.cs.wisc.edu/~strik/cs310.html'\n",
      " 'http://www.cs.wisc.edu/~deboor/deboor.html'\n",
      " 'http://www.cs.wisc.edu/~kunen/kunen.html'\n",
      " 'http://www.cs.wisc.edu/~paulb/paulb.html'\n",
      " 'http://www.cs.wisc.edu/~mbirk/cs302'\n",
      " 'http://www.cs.wisc.edu/~navin/navin.html'\n",
      " 'http://www.cs.wisc.edu/~galileo'\n",
      " 'http://www.cs.wisc.edu/~bestor/bestor.html'\n",
      " 'http://www.cs.wisc.edu/~tsiolis/tsiolis.html'\n",
      " 'http://www.cs.wisc.edu/~moshovos/moshovos.html'\n",
      " 'http://www.cs.wisc.edu/~plakal/plakal.html'\n",
      " 'http://www.cs.wisc.edu/~rahul/rahul.html'\n",
      " 'http://www.cs.wisc.edu/~yannis/yannis.html'\n",
      " 'http://www.cs.wisc.edu/~arch/uwarch/courses/cs552.html'\n",
      " 'http://www.cs.wisc.edu/~wenger/wenger.html'\n",
      " 'http://www.cs.wisc.edu/~paulb/paulb.html'\n",
      " 'http://www.cs.wisc.edu/~watrous/watrous.html'\n",
      " 'http://www.cs.wisc.edu/~seitz/animation.html'\n",
      " 'http://www.cs.wisc.edu/~cs537-2/cs537.html'\n",
      " 'http://www.cs.wisc.edu/~cs520-1/cs520.html']\n",
      "Page d'exemple: http://www.cs.wisc.edu/~cs737-1/cs737.html dans unlabeled : False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Constantes : \n",
    "path = 'WebKB/'\n",
    "univ = 'wisconsin'\n",
    "percentage_unlabeled = 0.1\n",
    "\n",
    "# On parse les données\n",
    "#path = '/Users/ACHANGER/Desktop/UPMC/FDMS-2/WebKB/'\n",
    "# Fichier 'content' contient des lignes « [URL]\\t[Attributs:suite de nombres]\\t[Étiquette] »\n",
    "content = pd.read_csv(path + 'content/'+univ+'.content', sep ='\\t', header=None)\n",
    "# Fichier 'cites' contient des liens « [destination] [source] »\n",
    "cites   = pd.read_csv(path + 'cites/'+univ+'.cites',     sep =' ', header=None)\n",
    "\n",
    "# Les identifiants des sites web sont leur URL :\n",
    "M = len(content)\n",
    "N = content.shape[1] - 2\n",
    "url = content.iloc[:,0] \n",
    "labels = content.iloc[:,-1] \n",
    "attributes = content.drop([0, N+1],axis=1)\n",
    "\n",
    "print(\"\\n=== url dataframe ===\")\n",
    "print(url.head())\n",
    "print(\"\\n=== labels dataframe ===\")\n",
    "print(labels.head())\n",
    "print(\"\\n=== attributes dataframe ===\")\n",
    "print(attributes.head())\n",
    "\n",
    "\n",
    "unlabeled = np.random.choice(url, size=int(M*percentage_unlabeled))\n",
    "print(\"\\nUnlabeled items:\")\n",
    "print(unlabeled)\n",
    "example_page = np.random.choice(url)\n",
    "print(\"Page d'exemple:\", example_page, \"dans unlabeled :\", example_page in unlabeled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voisins de http://www.cs.wisc.edu/~cs737-1/cs737.html :\n",
      "(url, label, unlabeled)\n",
      "[('http://www.cs.wisc.edu/~devise', 2, False)]\n"
     ]
    }
   ],
   "source": [
    "# Conversion des labels depuis string vers int\n",
    "url_to_labels = dict(zip(url, labels))\n",
    "unique_labels = sorted(np.unique(labels))\n",
    "labels_to_id = dict(zip(unique_labels, range(len(unique_labels))))\n",
    "url_pos = dict(zip(url, range(M)))\n",
    "\n",
    "# Parsing du réseau depuis fichier 'cites'\n",
    "network = {}\n",
    "for line in cites.iterrows():\n",
    "    src = line[1][1]\n",
    "    dest = line[1][0]\n",
    "    if src in network:\n",
    "        network[src].add(dest)\n",
    "    else:\n",
    "        network[src] = set([dest])\n",
    "\n",
    "print(\"Voisins de \"+example_page+\" :\")\n",
    "if example_page in network:\n",
    "    print(\"(url, label, unlabeled)\")\n",
    "    print([(v, labels_to_id[url_to_labels[v]], v in unlabeled) for v in network[example_page]])\n",
    "else:\n",
    "    print(\"Pas de citations depuis cette page\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voisinage de la page d'exemple : [ 0.  0.  1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Comptage des classes des voisins\n",
    "# Dans 'count' : 1 ligne = 1 url, 1 colonne = 1 classe (classes triées par ordre alphabétique) \n",
    "count = np.zeros((M, len(unique_labels)))\n",
    "\n",
    "# On itère sur tous les noeuds qui ont des liens sortants\n",
    "for noeud, voisins in network.items():\n",
    "    position = url_pos[noeud]\n",
    "    for voisin in network[noeud]:\n",
    "        voisin_label = labels_to_id[url_to_labels[voisin]]\n",
    "        if voisin not in unlabeled:\n",
    "            count[position, voisin_label] += 1\n",
    "            \n",
    "print(\"Voisinage de la page d'exemple :\", count[url_pos[example_page]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching best adaboost estimator\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Score : 0.8091286307053942\n",
      "Searching best rf estimator\n",
      "Fitting 3 folds for each of 320 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    4.8s finished\n",
      "[Parallel(n_jobs=-1)]: Done 293 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 569 tasks      | elapsed:   26.3s\n",
      "[Parallel(n_jobs=-1)]: Done 953 out of 960 | elapsed:   51.4s remaining:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.8464730290456431\n",
      "Searching best knn estimator\n",
      "Fitting 3 folds for each of 160 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 960 out of 960 | elapsed:   52.9s finished\n",
      "[Parallel(n_jobs=-1)]: Done 144 tasks      | elapsed:    2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.5684647302904564\n",
      "Searching best svc estimator\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed:    9.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.7717842323651453\n",
      "Aggrégation avec VotingClassifier\n",
      "Score sur le test set : 0.708333333333\n",
      "Proportion des labels : (array([0, 1, 2, 3, 4]), array([ 76,  35,  22,  10, 122]))\n",
      "Prédiction sur le test set : [4 1 0 0 0 4 4 4 4 4 4 0 4 4 4 2 0 1 2 0 4 4 4 4]\n",
      "Vrais labels : [1 1 0 0 4 4 4 4 4 0 0 0 4 1 2 2 0 1 2 0 4 4 4 3]\n"
     ]
    }
   ],
   "source": [
    "# Classification\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier \n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X = np.concatenate((np.array(attributes),count),axis=1)\n",
    "X_scale = preprocessing.scale(X)\n",
    "Y = np.array([labels_to_id[lab] for lab in labels])\n",
    "\n",
    "idx = set(range(M))\n",
    "test_idx = set([url_pos[u] for u in unlabeled])\n",
    "train_idx = list(idx - test_idx)\n",
    "test_idx = list(test_idx)\n",
    "\n",
    "X_train, X_test = X_scale[train_idx], X_scale[test_idx]\n",
    "Y_train, Y_test = Y[train_idx], Y[test_idx]\n",
    "true_labels = np.array([labels_to_id[lab] for lab in labels])[test_idx]\n",
    "\n",
    "\n",
    "estimators = {\"rf\":{\"clf\":RandomForestClassifier(),\n",
    "                    \"params\":{\"n_estimators\":np.arange(2, 100, 5),\n",
    "                              \"max_features\":(\"auto\", \"sqrt\", \"log2\", None),\n",
    "                              \"max_depth\":np.arange(2, 20, 5)}},\n",
    "              \"svc\":{\"clf\":SVC(),\n",
    "                     \"params\":{\"C\":np.logspace(-2, 2, 5),\n",
    "                              \"kernel\":(\"linear\", \"poly\", \"rbf\"),\n",
    "                              \"class_weight\":(None, \"balanced\")}},\n",
    "              \"knn\":{\"clf\":KNeighborsClassifier(),\n",
    "                     \"params\":{\"n_neighbors\":np.arange(2, 100, 5), \n",
    "                               \"weights\":(\"uniform\", \"distance\"), \n",
    "                               \"algorithm\":(\"auto\", \"ball_tree\", \"kd_tree\", \"brute\")}},\n",
    "              \"adaboost\":{\"clf\":AdaBoostClassifier(),\n",
    "                          \"params\":{\"base_estimator\":(None, RandomForestClassifier()), \n",
    "                                    \"n_estimators\":np.linspace(5, 50, 5, dtype=int), \n",
    "                                    \"learning_rate\":np.logspace(-1,1,3)}}\n",
    "             }\n",
    "\n",
    "choice = \"adaboost\"\n",
    "\n",
    "best_clf = None\n",
    "best_score = 0\n",
    "estimators_aggreg = []\n",
    "for choice in estimators.keys():\n",
    "    print(\"Searching best \"+choice+\" estimator\")\n",
    "    gridsearch = GridSearchCV(estimators[choice][\"clf\"], estimators[choice][\"params\"], n_jobs=-1, verbose=1)\n",
    "    gridsearch.fit(X_train, Y_train)\n",
    "    estimators_aggreg.append((choice, gridsearch.best_estimator_))\n",
    "    print(\"Score :\", gridsearch.best_score_)\n",
    "    if gridsearch.best_score_ > best_score:\n",
    "        best_clf = gridsearch.best_estimator_\n",
    "        best_score = gridsearch.best_score_\n",
    "\n",
    "print(\"Aggrégation avec VotingClassifier\")\n",
    "vote_clf = VotingClassifier(estimators_aggreg)\n",
    "vote_clf.fit(X_train, Y_train)\n",
    "#print(clf.get_params())\n",
    "\n",
    "if vote_clf.score(X_test, true_labels) > best_score:\n",
    "    best_clf = vote_clf\n",
    "\n",
    "print(\"Score sur le test set :\", best_clf.score(X_test, true_labels))\n",
    "print(\"Proportion des labels :\", np.unique(Y, return_counts=True))\n",
    "print(\"Prédiction sur le test set :\", best_clf.predict(X_test))\n",
    "print(\"Vrais labels :\", true_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2 : ICA\n",
    "\n",
    "On va réutiliser les données de la partie précédente pour la 1ère phase, _bootstraping_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimateur choisi : {'max_leaf_nodes': None, 'warm_start': False, 'min_samples_leaf': 1, 'random_state': None, 'n_estimators': 12, 'oob_score': False, 'verbose': 0, 'max_features': None, 'class_weight': None, 'bootstrap': True, 'min_weight_fraction_leaf': 0.0, 'n_jobs': 1, 'criterion': 'gini', 'min_samples_split': 2, 'max_depth': 7, 'min_impurity_split': 1e-07}\n",
      "[4 1 0 0 0 4 4 4 4 4 4 0 4 4 4 2 0 1 2 0 4 4 4 4] [1 1 0 0 4 4 4 4 4 0 0 0 4 1 2 2 0 1 2 0 4 4 4 3]\n",
      "(265, 1708)\n",
      "======= Itération 0 =======\n",
      "[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4] [1 1 0 0 4 4 4 4 4 0 0 0 4 1 2 2 0 1 2 0 4 4 4 3]\n",
      "======= Itération 1 =======\n",
      "[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4] [1 1 0 0 4 4 4 4 4 0 0 0 4 1 2 2 0 1 2 0 4 4 4 3]\n",
      "Fini.\n",
      "Score :  0.375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Estimateur choisi :\", best_clf.get_params())\n",
    "\n",
    "ordering = np.copy(test_idx)\n",
    "\n",
    "Y[test_idx] = best_clf.predict(X_test)\n",
    "old_labels = np.zeros_like(Y[test_idx]) - 1\n",
    "print(Y[test_idx], true_labels)\n",
    "\n",
    "max_iter = 5\n",
    "i = 0\n",
    "print(X.shape)\n",
    "while not np.allclose(old_labels, Y[test_idx]) and i<max_iter:\n",
    "    print(\"======= Itération %d =======\" % i)\n",
    "    # On itère sur tous les noeuds qui ont des liens sortants\n",
    "    np.random.shuffle(ordering)\n",
    "    for position in ordering:\n",
    "        noeud = url[position]\n",
    "        X[position, M:] = 0\n",
    "        #print(\"Noeud \"+noeud+\":\",X[position,M:])\n",
    "        if noeud in network:\n",
    "            for voisin in network[noeud]:\n",
    "                vlabel = Y[url_pos[voisin]]\n",
    "                #print(\"--- Nouveau voisin de label \",vlabel)\n",
    "                X[position, M+vlabel] += 1\n",
    "                #print(\"---\", X[position, M:])\n",
    "    old_labels = Y[test_idx]\n",
    "    Y[test_idx] = best_clf.predict(X[test_idx])\n",
    "    print(Y[test_idx], true_labels)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "print(\"Fini.\")\n",
    "print(\"Score : \", accuracy_score(Y[test_idx], true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
